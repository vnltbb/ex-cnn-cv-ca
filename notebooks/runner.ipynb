{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a188cfe",
   "metadata": {},
   "source": [
    "### 1. setting and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10665d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install module\n",
    "!pip install --upgrade pip\n",
    "!pip install pyyaml pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip uninstall keras -y\n",
    "!pip install \"tensorflow-macos>=2.16\"\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa08da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# 현재 실행 중인 노트북 기준 루트 디렉토리 잡기 (notebook과 config 폴더가 같은 상위 폴더에 있어야 함)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from config.load_config import load_config, load_config_win_env\n",
    "from data.split_dataset import data_count, split_dataset_by_class, extract_balanced_dataset\n",
    "from data.data_distribution import class_distribution\n",
    "from data.dataloader import get_generators, get_generators_non_seed\n",
    "from models.build_model import get_model\n",
    "from models.build_model import build_model\n",
    "from train.optimizer import get_optimizer\n",
    "from train.callbacks import get_callbacks\n",
    "from train.trainer import train_model\n",
    "from utils.evaluation import evaluate_model\n",
    "from utils.evaluation import plot_confusion_matrix\n",
    "from utils.evaluation import plot_train_history\n",
    "from utils.evaluation import show_top_misclassified\n",
    "from utils.evaluation import plot_metrics_text\n",
    "from utils.save_results import save_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e7025",
   "metadata": {},
   "source": [
    "### change the config path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c367e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config('/Users/vnlt/PROJECT/ex-cnn-cv/config/config.yaml')\n",
    "data_dir = f\"{config['base_output_dir']}/seed{config['seed']}\"\n",
    "batch_size = config['batch_size']\n",
    "save_dir = f\"results/{config['experiment_id']}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if config is loaded correctly\n",
    "print(type(config))\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4518c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and define preprocess_map for specific data generators to use\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, ResNet50, DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "preprocess_map = {\n",
    "    'MobileNetV2': mobilenet_preprocess,\n",
    "    'EfficientNetB0': efficientnet_preprocess,\n",
    "    'ResNet50': resnet_preprocess,\n",
    "    'DenseNet121': densenet_preprocess,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88eef19",
   "metadata": {},
   "source": [
    "### checkpoint-split dataset\n",
    "- select data split O/X\n",
    "- select data generator for ex-ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_image_counts, images, min_count = data_count(\n",
    "    original_dataset_dir=config['original_dataset_dir']\n",
    ")\n",
    "\n",
    "extract_balanced_dataset(\n",
    "    original_dataset_dir=config['original_dataset_dir'],\n",
    "    min_count=min_count,\n",
    "    base_output_dir=f\"{config['base_output_dir']}/seed{config['seed']}\",\n",
    "    seed=config['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0b923",
   "metadata": {},
   "source": [
    "#### data generators for verA, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d50474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generators - preprocessing and augmentation for A, B, C(except Full)\n",
    "train_gen, val_gen, test_gen = get_generators(\n",
    "    model_name=config['backbone_name'],\n",
    "    input_shape=tuple(config['input_shape']),\n",
    "    batch_size=config['batch_size'],\n",
    "    data_dir=f\"{config['base_output_dir']}/seed{config['seed']}\",\n",
    "    train_ratio=config['train_ratio'],\n",
    "    val_ratio=config['val_ratio'],\n",
    "    test_ratio=config['test_ratio'],\n",
    "    seed=config['seed'],\n",
    "    augmentations=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36ba54",
   "metadata": {},
   "source": [
    "#### data generators for verC-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generators for ver_C_full\n",
    "import glob\n",
    "\n",
    "def get_generators_non_seed(model_name, input_shape=(224, 224, 3), batch_size=None, data_dir=None,train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=None, augmentations=None):\n",
    "    if data_dir is None:\n",
    "        raise ValueError(\"❌ data_dir 값을 지정해야 합니다.\")\n",
    "    if augmentations is None:\n",
    "        augmentations = []\n",
    "\n",
    "    preprocess_func = preprocess_map[model_name]\n",
    "\n",
    "    # 이미지 경로 및 라벨 수집\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        image_files = glob.glob(os.path.join(class_path, '*'))  # 모든 확장자 허용\n",
    "        image_paths.extend(image_files)\n",
    "        labels.extend([class_name] * len(image_files))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'filename': image_paths,\n",
    "        'class': labels\n",
    "    })\n",
    "    \n",
    "    # 클래스별 stratified split\n",
    "    train_df, temp_df = train_test_split(df, stratify=df['class'], train_size=train_ratio, random_state=seed)\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        stratify=temp_df['class'],\n",
    "        test_size=test_ratio / (val_ratio + test_ratio),\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # generator setup\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "    \n",
    "    print(preprocess_func)\n",
    "    \n",
    "    # generator 생성\n",
    "    train_gen = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_gen = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    test_gen = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "train_gen, val_gen, test_gen = get_generators_non_seed(\n",
    "    model_name=config['backbone_name'],\n",
    "    input_shape=tuple(config['input_shape']),\n",
    "    batch_size=config['batch_size'],\n",
    "    data_dir=\"/Users/vnlt/PROJECT/ex-cnn-cv/data/dataset/seed99\", # f\"{config['original_dataset_dir']}\",\n",
    "    train_ratio=config['train_ratio'],\n",
    "    val_ratio=config['val_ratio'],\n",
    "    test_ratio=config['test_ratio'],\n",
    "    seed=config['seed'],\n",
    "    augmentations=config['augmentations']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8c79d",
   "metadata": {},
   "source": [
    "#### data generators for verD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37706056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generators for ver_D\n",
    "\n",
    "def get_generators(model_name, input_shape=(224, 224, 3), batch_size=None, data_dir=None,train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=None, augmentations=None):\n",
    "    if data_dir is None:\n",
    "        raise ValueError(\"❌ data_dir 값을 지정해야 합니다.\")\n",
    "    if augmentations is None:\n",
    "        augmentations = []\n",
    "\n",
    "    preprocess_func = preprocess_map[model_name]\n",
    "    \n",
    "    # 이미지 경로 및 라벨 수집\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for cls in os.listdir(data_dir):\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        image_files = glob.glob(os.path.join(cls_path, '*'))  # 모든 확장자 허용\n",
    "        image_paths.extend(image_files)\n",
    "        labels.extend([cls] * len(image_files))\n",
    "\n",
    "    df = pd.DataFrame({'filename': image_paths, 'class': labels})\n",
    "    \n",
    "    # 클래스별 stratified split\n",
    "    train_df, temp_df = train_test_split(df, stratify=df['class'], train_size=train_ratio, random_state=seed)\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        stratify=temp_df['class'],\n",
    "        test_size=test_ratio / (val_ratio + test_ratio),\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # generator setup\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func,\n",
    "        rotation_range=config['rotation_range'],\n",
    "        width_shift_range=config['width_shift_range'],\n",
    "        height_shift_range=config['height_shift_range'],\n",
    "        zoom_range=config['zoom_range'],\n",
    "        horizontal_flip=config['horizontal_flip'],\n",
    "        vertical_flip=config['vertical_flip'],\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "    \n",
    "    print(preprocess_func)\n",
    "    \n",
    "    # generator 생성\n",
    "    train_gen = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        directory=None\n",
    "    )\n",
    "\n",
    "    val_gen = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        directory=None  \n",
    "    )\n",
    "\n",
    "    test_gen = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        directory=None\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "train_gen, val_gen, test_gen = get_generators(\n",
    "    model_name=config['backbone_name'],\n",
    "    input_shape=tuple(config['input_shape']),\n",
    "    batch_size=config['batch_size'],\n",
    "    data_dir=f\"{config['base_output_dir']}/seed{config['seed']}\",\n",
    "    train_ratio=config['train_ratio'],\n",
    "    val_ratio=config['val_ratio'],\n",
    "    test_ratio=config['test_ratio'],\n",
    "    seed=config['seed'],\n",
    "    augmentations=config['augmentations']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0192203",
   "metadata": {},
   "source": [
    "### check data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    test_gen,\n",
    "    config,\n",
    "    save_path=f\"{save_dir}/dist_table.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7ad3f",
   "metadata": {},
   "source": [
    "### 2. model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e335e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "model = build_model(\n",
    "    backbone_name=config['backbone_name'],\n",
    "    input_shape=tuple(config['input_shape']),\n",
    "    num_classes=config['num_classes'],\n",
    "    dropout_rate=config['dropout_rate']\n",
    ")\n",
    "# compile model\n",
    "optimizer = get_optimizer(\n",
    "    optimizer_name=config['optimizer'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    weight_decay=config.get('weight_decay', 0.0)\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(\n",
    "    model_name=config['backbone_name'],\n",
    "    save_dir=f\"results/{config['experiment_id']}\",\n",
    "    patience=config['patience']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "history = train_model(\n",
    "    model,\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae09f6",
   "metadata": {},
   "source": [
    "### 3. evaluation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db214c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_prob = evaluate_model(model, test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class indices\n",
    "print(\"Original class_indices (class name → index):\")\n",
    "print(test_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913949a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(test_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c312ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results visualization\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": report[\"accuracy\"],\n",
    "    \"precision\": report[\"macro avg\"][\"precision\"],\n",
    "    \"recall\": report[\"macro avg\"][\"recall\"],\n",
    "    \"f1_score\": report[\"macro avg\"][\"f1-score\"]\n",
    "}\n",
    "\n",
    "plot_metrics_text(\n",
    "    metrics_dict=metrics_dict,\n",
    "    experiment_id=config['experiment_id'],\n",
    "    save_path=f\"{save_dir}/metrics_text.png\"\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    cm, \n",
    "    class_names, \n",
    "    title=\"Confusion Matrix\", \n",
    "    save_path=f\"{save_dir}/confusion_matrix.png\"\n",
    ")\n",
    "plot_train_history(\n",
    "    history,\n",
    "    save_path=f\"{save_dir}/history_graph.png\"\n",
    ")\n",
    "\n",
    "show_top_misclassified(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_prob,\n",
    "    class_names,\n",
    "    generator=test_gen,\n",
    "    model_name=config['experiment_id'],\n",
    "    save_dir=save_dir,\n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624f66d",
   "metadata": {},
   "source": [
    "### 4. results save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_results(\n",
    "    model_name=config['backbone_name'],\n",
    "    history=history,\n",
    "    cm=confusion_matrix(y_true, y_pred),\n",
    "    class_names=list(test_gen.class_indices.keys()),\n",
    "    report=classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys()), output_dict=True),\n",
    "    save_dir= save_dir\n",
    ")\n",
    "\n",
    "print(f\"\\u2705 저장 완료: {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
